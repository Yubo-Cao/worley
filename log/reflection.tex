\reflection{7/1/2023}{Anish Goyal}

For our \href{https://gosa.georgia.gov/governors-honors-program}{\gls{gosa} \gls{ghp}} final engineering project, we wanted to create an innovative device that could improve the lives of others. Our best friend, Cory, suffers from hearing loss and has to use hearing aids or sign language to communicate properly. This inspired us to create an application that signs out the \gls{asl} alphabet using a mechanical robot hand from voice input in real time.

Even though it's the first day, we have already faced skepticism from our engineering instructors regarding our ability to achieve ten \gls{dof} within a tight timeframe of two weeks. However, this skepticism has only fueled our determination to prove them wrong.

Here is some of the stuff we came up with during our brainstorming session today:
\begin{description}
\item[Pybluez] This Python library allowed us to establish a Bluetooth connection between our mobile application and the robot hand. It provided an interface to communicate and control the hand's movements seamlessly.

\item[RPI GPIO programming] To interface with the robot hand, we leveraged \gls{rpi}'s \gls{gpio} pins. By connecting our servos to pins, we will be able to control the hand's actuators and enable precise finger movements.

\item[UDP and Custom audio transmission protocol] We want to implement \gls{udp} to transmit audio data from the mobile application to the signal processing module. We could also design a custom audio transmission protocol to ensure efficient and reliable data transfer.

\item[Zero-copy memory-efficient thread-safe asynchronous queue] This concept will help us optimize the data processing pipeline by minimizing memory overhead and ensuring thread safety. By utilizing an asynchronous queue, we can achieve efficient parallel processing of audio data.

\item[Real time speech recognition through Whisper] We want to integrate cutting-edge techniques such as sliding window-based speech recognition and speaker diarization using the Whisper \gls{asr} model by OpenAI. Cutting the live audio into segments and feeding them into Whisper yields an accurate transcription of voice input with the illusion of real-time recognition.

\item[Kubeflow-powered ML operations] We want to employ Kubeflow, a \gls{ml} toolkit for Kubernetes, to build a robust \gls{ml} pipeline. With Kubeflow, we can ensure data provenance, making it possible to trace and understand the entire ML workflow.

[Ray cluster-powered hyperparameter tuning] Using Ray, an open-source framework for distributed computing to optimize our ML models, will greatly accelerate the process of hyperparameter tuning, enabling better feature recognition and extraction.
\end{description}
\newpage

\reflection{7/3/2023}{Yubo Cao}

Throughout the last Saturday \& Sunday, we have been working on a presentation for the project pitch, computer-aided design (CAD) of the model, \& the preliminary testing of the servo motion. Research on existing solutions of speech recognition, speaker diarisation (SD), voice activation detection (VAD), \& speech-to-text (STT) has also been conducted. However, After the meeting with Mr.~Kai, we have decided to focus on the implementation of robotic finger and hand, creating the backlog \& minimum viable product list (MVP), and following an incremental goal to assure the project's success in the end.

\newpage
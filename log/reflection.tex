\reflection{7/1/2023}{Anish Goyal}

For our \href{https://gosa.georgia.gov/governors-honors-program}{\gls{gosa} \gls{ghp}} final engineering project, we wanted to create an innovative device that could improve the lives of others. Our best friend, Cory, suffers from hearing loss and has to use hearing aids or sign language to communicate properly. This inspired us to create an application that signs out the \gls{asl} alphabet using a mechanical robot hand from voice input in real time.

Even though it's the first day, we have already faced skepticism from our engineering instructors regarding our ability to achieve ten \gls{dof} within a tight timeframe of two weeks. However, this skepticism has only fueled our determination to prove them wrong.

Here is some of the stuff we came up with during our brainstorming session today:
\begin{description}
\item[Pybluez] This Python library allows us to establish a Bluetooth connection between the computer controller and the \gls{rpi}-controlled robot hand. It also provides an interface to seamlessly communicate with the hand.

\item[RPI GPIO programming] To interface with the robot hand, we leveraged \gls{rpi}'s \gls{gpio} pins. By connecting our servos to pins, we will be able to control the hand's actuators and enable precise finger movements.

\item[UDP and Custom audio transmission protocol] We want to implement \gls{udp} to transmit audio data from the mobile application to the signal processing module. We could also design a custom audio transmission protocol to ensure efficient and reliable data transfer.

\item[Zero-copy memory-efficient thread-safe asynchronous queue] This concept will help us optimize the data processing pipeline by minimizing memory overhead and ensuring thread safety. By utilizing an asynchronous queue, we can achieve efficient parallel processing of audio data.

\item[Real time speech recognition through Whisper] We want to integrate cutting-edge techniques such as sliding window-based speech recognition and speaker diarization using the Whisper \gls{asr} model by OpenAI. Cutting the live audio into segments and feeding them into Whisper yields an accurate transcription of voice input with the illusion of real-time recognition.

\item[Kubeflow-powered ML operations] We want to employ Kubeflow, a \gls{ml} toolkit for Kubernetes, to build a robust \gls{ml} pipeline. With Kubeflow, we can ensure data provenance, making it possible to trace and understand the entire ML workflow.

[Ray cluster-powered hyperparameter tuning] Using Ray, an open-source framework for distributed computing to optimize our ML models, will greatly accelerate the process of hyperparameter tuning, enabling better feature recognition and extraction.
\end{description}
\newpage

\reflection{7/3/2023}{Yubo Cao}

Over the past two days, we have been working on a presentation for the project pitch, \gls{cad} of the model, \& the preliminary testing of the servo motion. We also researched existing solutions on speech recognition, \gls{sd}, \gls{vad}, \& \gls{stt}. After our meeting with Mr. Kai, the \gls{cs} department head at \gls{ghp}, we have decided to focus on the implementation of the robotic finger and hand, creating a backlog \& \gls{mvp} list, and following an incremental goal structure to assure the project's success in the end.

\newpage